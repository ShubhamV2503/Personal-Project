AI-Powered Augmented Reality (AR) Navigation System for Visually Impaired Individuals   
Overview   
This project is an AI-powered Augmented Reality (AR) navigation system designed to assist visually impaired individuals in navigating their surroundings. The system utilizes computer vision, object detection, and real-time audio feedback to detect obstacles, recognize objects, and provide clear path guidance.

Features  
âœ… Object Detection & Recognition â€“ Uses YOLOv8 for real-time object detection.  
âœ… Distance Estimation â€“ Calculates distance to obstacles to provide relevant alerts.    
âœ… Audio Feedback System â€“ Uses text-to-speech (TTS) to guide users via voice commands.  
âœ… Real-Time Navigation â€“ Ensures safe movement by directing users to an obstacle-free path.  
âœ… Gesture & Voice Commands â€“ Allows users to interact using simple gestures or voice.  
âœ… GPS Integration â€“ (Planned for future updates) Provides location-based navigation.  

Technologies Used  
YOLOv8 â€“ Object detection & recognition  
OpenCV â€“ Image processing  
PyTorch â€“ Deep learning framework  
Pyttsx3 â€“ Offline text-to-speech conversion    
SpeechRecognition â€“ Voice command integration  
OpenCV + AI â€“ Distance estimation & obstacle tracking  

INSTALLATION & SETUP  
1ï¸âƒ£ Clone the Repository  
```
git clone https://github.com/SSarkar0307/AI-Powered-Augmented-Reality-AR-Navigation-System-for-Visually-Impaired-Individuals.git
cd AI-Powered-Augmented-Reality-AR-Navigation-System-for-Visually-Impaired-Individuals

```
2ï¸âƒ£ Install Dependencies  
```
pip install -r requirements.txt

```

Challenges & Improvements  
ğŸ”´ Latency Issues â€“ Optimized model to improve real-time performance.  
ğŸ”´ Distance Estimation Accuracy â€“ Refined calculations to reduce false alerts.  
ğŸ”´ Voice Delay â€“ Switched to an offline TTS engine for faster responses.  
ğŸ”´ Hardware Limitations â€“ Balanced accuracy and speed for smoother execution.  
ğŸ”´ Object Recognition â€“ Improved detection for better scene understanding.  

Future Scope  
ğŸ”¹ Wearable Implementation - Convert this into smart glasses for hands-free navigation  
ğŸ”¹ GPS-Based Navigation â€“ Implement location-based path guidance.    
ğŸ”¹ Haptic Feedback â€“ Integrate vibration alerts for obstacle proximity.  
ğŸ”¹ Cloud-Based Model Updates â€“ Improve detection accuracy over time.  
ğŸ”¹ Multilingual Support â€“ Extend voice guidance to multiple languages.  

Contributors  
ğŸ‘¨â€ğŸ’» Sohan Sarkar â€“ Lead Developer & Researcher  
    
Feel free to contribute or reach out for collaboration! ğŸš€
