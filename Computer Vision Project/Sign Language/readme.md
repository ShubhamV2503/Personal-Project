
## ğŸ“Œ Overview

Provide a concise description of the project, its purpose, and what problem it solves. Mention the key technologies or tools used and the primary functionality. Aim for 2-4 sentences to give readers a quick understanding.

## ğŸ› ï¸ Features
- ğŸ“· **Real-time webcam feed processing**
- âœ‹ **Detects numbers and words from hand signs**
- ğŸ¯ **Ensures one of the hands are detected for accurate predictions**
- ğŸ“Š **Filters out low-confidence predictions to reduce errors**


## ğŸ‘¥ Who Can Use This?

   This project can be used by:

   ğŸ« Students & Researchers working on AI-based gesture recognition.

  ğŸ§â€â™‚ï¸ Deaf & Hard of Hearing Individuals to communicate via sign language.

  ğŸ“± Developers & Engineers to integrate sign recognition into applications.
  
  ğŸ“ Educators & Institutions for learning and teaching sign language.

## âœ… How This Project is Useful
- Bridges communication gaps between hearing-impaired and non-signers.
- Automates sign language recognition, making it easier for accessibility solutions.
- Enhances learning experiences by providing real-time feedback on sign gestures.
- Can be integrated with AI assistants for hands-free communication.

## ğŸš€ Getting Started
ğŸ“¦ Requirements
- Prerequisites
- Python 3.x
- Jupyter
- OpenCV
- MediaPipe
- TensorFlow/Keras
- NumPy

## ğŸ›  Steps to Run
### 1ï¸âƒ£ Install Dependencies
Ensure you have **Python 3.7+** installed, then run:
```bash
pip install numpy opencv-python mediapipe tensorflow
```

### 2ï¸âƒ£ Clone the Repository
```bash
git clone git@github.com:Amatullagajipurwala/HandSpeak.git
```

###  3ï¸âƒ£ Run Project
```bash
jupyter notebook
```

### 4ï¸âƒ£ Controls
- Press **'Q'** to **exit** the application.

## ğŸ¯ How It Works
1. **Captures Webcam Input** ğŸ¥
   - Reads frames continuously from the webcam.
2. **Extracts Hand Keypoints** ğŸ–
   - Uses **MediaPipe Holistic** to track hand landmarks.
3. **Predicts the Sign** ğŸ”¤
   - Uses a **pretrained model** to classify the sign (number/word).
4. **Displays the Word on Screen** ğŸ–¥
   - If confidence is high, the detected word is displayed.
5. **Ignores Incorrect or No-Hand Cases** ğŸš«
   - If both hands are not detected, the display remains empty.
  




